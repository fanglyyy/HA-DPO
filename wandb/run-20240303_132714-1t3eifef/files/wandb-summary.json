{"train/loss": 0.5416, "train/learning_rate": 1.9740972435213112e-06, "train/rewards/chosen": -1.529400110244751, "train/rewards/rejected": -1.9341578483581543, "train/rewards/accuracies": 0.8125, "train/rewards/margins": 0.4047577977180481, "train/policy_logps/rejected": -1306.4224853515625, "train/policy_logps/chosen": -1156.31494140625, "train/referece_logps/rejected": -1287.0809326171875, "train/referece_logps/chosen": -1141.0208740234375, "train/logits/rejected": 1.8988385200500488, "train/logits/chosen": 1.9108248949050903, "train/epoch": 0.1, "train/global_step": 32, "_timestamp": 1709444838.4284408, "_runtime": 1203.5036659240723, "_step": 31}