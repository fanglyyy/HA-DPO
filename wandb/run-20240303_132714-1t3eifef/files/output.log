  0%|                                                                                                                                              | 0/313 [00:00<?, ?it/s]/root/autodl-tmp/HA-DPO/ha_dpo/trainer/llava_dpo_trainer.py:135: UserWarning: compute_loss is only implemented for DPODataCollatorWithPadding, and you passed a datacollator that is different than DPODataCollatorWithPadding - you might see unexpected behavior. Alternatively, you can implement your own prediction_step method if you are using a custom data collator
  warnings.warn(
Could not estimate the number of tokens of the input, floating-point operations will not be computed
  0%|▍                                                                                                                                   | 1/313 [00:45<3:56:50, 45.55s/it]
{'loss': 0.6931, 'learning_rate': 2e-07, 'rewards/chosen': 0.0, 'rewards/rejected': 0.0, 'rewards/accuracies': 0.0, 'rewards/margins': 0.0, 'policy_logps/rejected': -917.870849609375, 'policy_logps/chosen': -819.0548706054688, 'referece_logps/rejected': -917.870849609375, 'referece_logps/chosen': -819.0548706054688, 'logits/rejected': 1.8736339807510376, 'logits/chosen': 1.879775047302246, 'epoch': 0.0}


  1%|█▎                                                                                                                                  | 3/313 [01:55<3:13:13, 37.40s/it]
{'loss': 0.6836, 'learning_rate': 6e-07, 'rewards/chosen': 0.014598655514419079, 'rewards/rejected': -0.005328368861228228, 'rewards/accuracies': 0.6875, 'rewards/margins': 0.019927024841308594, 'policy_logps/rejected': -1115.0091552734375, 'policy_logps/chosen': -1091.06494140625, 'referece_logps/rejected': -1114.9559326171875, 'referece_logps/chosen': -1091.2109375, 'logits/rejected': 1.8648262023925781, 'logits/chosen': 1.871431589126587, 'epoch': 0.01}


  2%|██                                                                                                                                  | 5/313 [03:06<3:05:16, 36.09s/it]
{'loss': 0.6976, 'learning_rate': 1e-06, 'rewards/chosen': -0.0039764405228197575, 'rewards/rejected': 0.0044314381666481495, 'rewards/accuracies': 0.4375, 'rewards/margins': -0.008407878689467907, 'policy_logps/rejected': -840.7205810546875, 'policy_logps/chosen': -833.2213745117188, 'referece_logps/rejected': -840.7649536132812, 'referece_logps/chosen': -833.1815185546875, 'logits/rejected': 1.8416231870651245, 'logits/chosen': 1.855245590209961, 'epoch': 0.02}


  2%|██▉                                                                                                                                 | 7/313 [04:16<3:01:05, 35.51s/it]
{'loss': 0.7006, 'learning_rate': 1.4e-06, 'rewards/chosen': -0.039194487035274506, 'rewards/rejected': -0.02490091323852539, 'rewards/accuracies': 0.3125, 'rewards/margins': -0.014293573796749115, 'policy_logps/rejected': -992.5518188476562, 'policy_logps/chosen': -868.1947021484375, 'referece_logps/rejected': -992.302734375, 'referece_logps/chosen': -867.8027954101562, 'logits/rejected': 1.8827813863754272, 'logits/chosen': 1.8874262571334839, 'epoch': 0.02}


  3%|███▊                                                                                                                                | 9/313 [05:26<2:58:12, 35.17s/it]
{'loss': 0.6949, 'learning_rate': 1.8e-06, 'rewards/chosen': -0.07928018271923065, 'rewards/rejected': -0.07655505836009979, 'rewards/accuracies': 0.5, 'rewards/margins': -0.0027251243591308594, 'policy_logps/rejected': -886.7086791992188, 'policy_logps/chosen': -912.649169921875, 'referece_logps/rejected': -885.9429931640625, 'referece_logps/chosen': -911.8563842773438, 'logits/rejected': 1.8811954259872437, 'logits/chosen': 1.9051876068115234, 'epoch': 0.03}

  3%|████▏                                                                                                                              | 10/313 [06:23<3:31:33, 41.89s/it]

  4%|████▌                                                                                                                              | 11/313 [06:59<3:21:34, 40.05s/it]

  4%|█████                                                                                                                              | 12/313 [07:34<3:13:43, 38.62s/it]


  4%|█████▊                                                                                                                             | 14/313 [08:51<3:13:12, 38.77s/it]

  5%|██████▎                                                                                                                            | 15/313 [09:26<3:07:45, 37.81s/it]

  5%|██████▋                                                                                                                            | 16/313 [10:01<3:02:13, 36.81s/it]
{'loss': 0.7014, 'learning_rate': 1.998065597133594e-06, 'rewards/chosen': -0.5667755007743835, 'rewards/rejected': -0.5549458861351013, 'rewards/accuracies': 0.625, 'rewards/margins': -0.011829660274088383, 'policy_logps/rejected': -879.1163330078125, 'policy_logps/chosen': -949.05029296875, 'referece_logps/rejected': -873.5669555664062, 'referece_logps/chosen': -943.3826904296875, 'logits/rejected': 1.8591723442077637, 'logits/chosen': 1.872489094734192, 'epoch': 0.05}


  6%|███████▌                                                                                                                           | 18/313 [11:10<2:54:57, 35.58s/it]

  6%|███████▉                                                                                                                           | 19/313 [11:45<2:53:48, 35.47s/it]

  6%|████████▎                                                                                                                          | 20/313 [12:20<2:52:46, 35.38s/it]

  7%|████████▊                                                                                                                          | 21/313 [12:56<2:53:45, 35.70s/it]

  7%|█████████▏                                                                                                                         | 22/313 [13:32<2:52:20, 35.53s/it]

  7%|█████████▋                                                                                                                         | 23/313 [14:08<2:52:57, 35.78s/it]
{'loss': 0.6282, 'learning_rate': 1.9909298684723905e-06, 'rewards/chosen': -1.182557225227356, 'rewards/rejected': -1.3488945960998535, 'rewards/accuracies': 0.6875, 'rewards/margins': 0.16633740067481995, 'policy_logps/rejected': -1184.6600341796875, 'policy_logps/chosen': -1071.598388671875, 'referece_logps/rejected': -1171.171142578125, 'referece_logps/chosen': -1059.77294921875, 'logits/rejected': 1.8730595111846924, 'logits/chosen': 1.877656102180481, 'epoch': 0.07}

  8%|██████████                                                                                                                         | 24/313 [14:55<3:08:33, 39.15s/it]


  8%|█████████▉                                                                                                             | 26/313 [16:20<3:19:29, 41.71s/it]

  9%|██████████▎                                                                                                            | 27/313 [16:56<3:10:41, 40.01s/it]

  9%|██████████▋                                                                                                            | 28/313 [17:31<3:02:49, 38.49s/it]

  9%|███████████                                                                                                            | 29/313 [18:06<2:57:29, 37.50s/it]

 10%|███████████▍                                                                                                           | 30/313 [18:42<2:54:25, 36.98s/it]

 10%|███████████▊                                                                                                           | 31/313 [19:17<2:50:50, 36.35s/it]
{'loss': 0.6183, 'learning_rate': 1.976389420563607e-06, 'rewards/chosen': -1.131849765777588, 'rewards/rejected': -1.3423199653625488, 'rewards/accuracies': 0.625, 'rewards/margins': 0.21047022938728333, 'policy_logps/rejected': -940.095458984375, 'policy_logps/chosen': -924.6031494140625, 'referece_logps/rejected': -926.6721801757812, 'referece_logps/chosen': -913.28466796875, 'logits/rejected': 1.8512638807296753, 'logits/chosen': 1.8740037679672241, 'epoch': 0.1}

