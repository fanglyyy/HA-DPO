  0%|                                                                                                                                       | 0/1 [00:00<?, ?it/s]/root/autodl-tmp/HA-DPO/ha_dpo/trainer/llava_dpo_trainer.py:135: UserWarning: compute_loss is only implemented for DPODataCollatorWithPadding, and you passed a datacollator that is different than DPODataCollatorWithPadding - you might see unexpected behavior. Alternatively, you can implement your own prediction_step method if you are using a custom data collator
  warnings.warn(
Could not estimate the number of tokens of the input, floating-point operations will not be computed
100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:19<00:00, 19.95s/it]
{'loss': 0.2166, 'learning_rate': 2e-06, 'rewards/chosen': 0.0, 'rewards/rejected': 0.0, 'rewards/accuracies': 0.0, 'rewards/margins': 0.0, 'policy_logps/rejected': -24.281766891479492, 'policy_logps/chosen': -17.104846954345703, 'referece_logps/rejected': -24.281766891479492, 'referece_logps/chosen': -17.104846954345703, 'logits/rejected': -0.31440091133117676, 'logits/chosen': 1.6903560161590576, 'epoch': 1.0}
{'train_runtime': 22.5074, 'train_samples_per_second': 0.222, 'train_steps_per_second': 0.044, 'train_loss': 0.21660849452018738, 'epoch': 1.0}
Traceback (most recent call last):
  File "/root/autodl-tmp/HA-DPO/ha_dpo/models/llava-v1_5/train_dpo.py", line 814, in <module>
    main()
  File "/root/autodl-tmp/HA-DPO/ha_dpo/models/llava-v1_5/train_dpo.py", line 811, in main
    dpo_trainer.train()
  File "/root/autodl-tmp/condaenv/env_HA-DPO/lib/python3.9/site-packages/transformers/trainer.py", line 1539, in train
    return inner_training_loop(
  File "/root/autodl-tmp/condaenv/env_HA-DPO/lib/python3.9/site-packages/transformers/trainer.py", line 1971, in _inner_training_loop
    self.control = self.callback_handler.on_train_end(args, self.state, self.control)
  File "/root/autodl-tmp/condaenv/env_HA-DPO/lib/python3.9/site-packages/transformers/trainer_callback.py", line 356, in on_train_end
    return self.call_event("on_train_end", args, state, control)
  File "/root/autodl-tmp/condaenv/env_HA-DPO/lib/python3.9/site-packages/transformers/trainer_callback.py", line 397, in call_event
    result = getattr(callback, event)(
  File "/root/autodl-tmp/HA-DPO/ha_dpo/models/llava-v1_5/train_dpo.py", line 486, in on_train_end
    non_lora_state_dict = get_peft_state_non_lora_maybe_zero_3(
  File "/root/autodl-tmp/HA-DPO/ha_dpo/models/llava-v1_5/train_dpo.py", line 472, in get_peft_state_non_lora_maybe_zero_3
    to_return = {k: maybe_zero_3(v, ignore_status=True).cpu() for k, v in to_return.items()}
  File "/root/autodl-tmp/HA-DPO/ha_dpo/models/llava-v1_5/train_dpo.py", line 472, in <dictcomp>
    to_return = {k: maybe_zero_3(v, ignore_status=True).cpu() for k, v in to_return.items()}
  File "/root/autodl-tmp/HA-DPO/ha_dpo/models/llava-v1_5/train_dpo.py", line 439, in maybe_zero_3
    param = param.data.detach().cpu().clone()
  File "/root/autodl-tmp/condaenv/env_HA-DPO/lib/python3.9/site-packages/deepspeed/runtime/zero/partition_parameters.py", line 1673, in __exit__
    self.params[0].partition(param_list=self.params, has_been_updated=False)
  File "/root/autodl-tmp/condaenv/env_HA-DPO/lib/python3.9/site-packages/deepspeed/runtime/zero/partition_parameters.py", line 966, in partition
    self._partition(param_list, has_been_updated=has_been_updated)
  File "/root/autodl-tmp/condaenv/env_HA-DPO/lib/python3.9/site-packages/deepspeed/runtime/zero/partition_parameters.py", line 1104, in _partition
    self._partition_param(param, has_been_updated=has_been_updated)
  File "/root/autodl-tmp/condaenv/env_HA-DPO/lib/python3.9/site-packages/deepspeed/utils/nvtx.py", line 15, in wrapped_fn
    ret_val = func(*args, **kwargs)
  File "/root/autodl-tmp/condaenv/env_HA-DPO/lib/python3.9/site-packages/deepspeed/runtime/zero/partition_parameters.py", line 1137, in _partition_param
    free_param(param)
  File "/root/autodl-tmp/condaenv/env_HA-DPO/lib/python3.9/site-packages/deepspeed/utils/nvtx.py", line 15, in wrapped_fn
    ret_val = func(*args, **kwargs)
  File "/root/autodl-tmp/condaenv/env_HA-DPO/lib/python3.9/site-packages/deepspeed/runtime/zero/partition_parameters.py", line 271, in free_param
    assert not param.ds_active_sub_modules, param.ds_summary()
AssertionError: {'id': 1815, 'status': 'AVAILABLE', 'numel': 4194304, 'ds_numel': 4194304, 'shape': (4096, 1024), 'ds_shape': (4096, 1024), 'requires_grad': True, 'grad_shape': None, 'persist': False, 'active_sub_modules': {3301}, 'ds_tensor.shape': torch.Size([4194304])}