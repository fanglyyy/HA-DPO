{"train/loss": 0.6994, "train/learning_rate": 1e-06, "train/rewards/chosen": -0.005419159308075905, "train/rewards/rejected": 0.006649971008300781, "train/rewards/accuracies": 0.4375, "train/rewards/margins": -0.012069128453731537, "train/policy_logps/rejected": -840.7113037109375, "train/policy_logps/chosen": -833.286865234375, "train/referece_logps/rejected": -840.7777099609375, "train/referece_logps/chosen": -833.2326049804688, "train/logits/rejected": 1.84214448928833, "train/logits/chosen": 1.8540408611297607, "train/epoch": 0.02, "train/global_step": 5, "_timestamp": 1718290921.9186885, "_runtime": 168.95930862426758, "_step": 4}